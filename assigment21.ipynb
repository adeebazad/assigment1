{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3983a201-5ef5-46aa-a78d-dda12bf71c78",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Ans-\n",
    "\n",
    "Web scraping is a technique of extracting data from websites using automated software tools, commonly referred to as web scrapers or web crawlers. The primary purpose of web scraping is to collect large amounts of data from websites quickly and efficiently, which can then be used for various purposes like market research, data analysis, and content creation.\n",
    "\n",
    "Three areas where web scraping is commonly used to get data are:\n",
    "\n",
    "E-commerce: Web scraping is often used to monitor competitor prices, gather product data, and analyze trends in e-commerce businesses.\n",
    "\n",
    "Research: Researchers use web scraping to collect data from various sources, including social media, news websites, and online databases.\n",
    "\n",
    "Business Intelligence: Web scraping is used to gather data on potential customers, track trends in consumer behavior, and monitor competitors in business intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927a24d-4748-4f24-9204-b748d804abc9",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "Ans-\n",
    "\n",
    "There are several methods for web scraping, including:\n",
    "\n",
    "Manual Scraping: This involves manually copying and pasting data from web pages.\n",
    "\n",
    "Web Scraping Tools: There are various web scraping tools available, such as Scrapy, Beautiful Soup, and Selenium, which can automate the web scraping process.\n",
    "\n",
    "APIs: Some websites provide APIs that allow developers to access their data directly, eliminating the need for web scraping.\n",
    "\n",
    "Crawlers: Crawlers are software programs that automatically explore the web, visiting multiple websites and gathering data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7860084-ca01-40d5-8e60-fa933b2080e5",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Ans-\n",
    "\n",
    "Beautiful Soup is a Python library used for web scraping purposes to parse HTML and XML documents. It provides a simple and efficient way to navigate and search the tree-like structure of HTML and XML documents.\n",
    "\n",
    "Beautiful Soup is used for web scraping because it provides a convenient and flexible way to extract data from websites. It can handle malformed HTML and XML documents and can parse data from complex web pages. Beautiful Soup also provides a wide range of features, including searching for tags, searching for attributes, and navigating the document tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46904b63-07ae-459c-a81b-0300c4b8cfae",
   "metadata": {},
   "source": [
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Ans-\n",
    "\n",
    "Flask is a lightweight and flexible web framework for Python that is commonly used for building web applications. Flask is used in this web scraping project to create a web interface for users to access the scraped data.\n",
    "\n",
    "Flask provides a simple and easy-to-use interface for building web applications, making it an ideal choice for small to medium-sized web applications. Flask also provides a wide range of extensions and plugins that can be used to add additional functionality to the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e3312-ed70-4b7f-874e-bbef09fe6c3f",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "Ans-\n",
    "\n",
    "In this web scraping project, the following AWS services are used:\n",
    "\n",
    "Amazon S3: S3 is used to store the scraped data in a bucket, providing a scalable and secure storage solution for the data.\n",
    "\n",
    "AWS Lambda: Lambda is used to execute the scraping script automatically at regular intervals, ensuring that the data is always up-to-date.\n",
    "\n",
    "Amazon CloudWatch: CloudWatch is used to monitor the Lambda function and provide metrics and logs for debugging and troubleshooting purposes.\n",
    "\n",
    "Amazon API Gateway: API Gateway is used to provide a RESTful API for users to access the scraped data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
